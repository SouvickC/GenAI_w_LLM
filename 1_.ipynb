{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c02f3972",
      "metadata": {
        "id": "c02f3972"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchdata\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig\n",
        "import huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wlRY2Az6VjlM"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"knkarthick/dialogsum\")"
      ],
      "id": "wlRY2Az6VjlM"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "noviQyIxVjlM",
        "outputId": "87005e76-2ecc-4d93-d0bf-65402472552e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________________________________________\n",
            "Example 1\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "___________________________________________________________________________________________________\n",
            "Baseline Human summary\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "___________________________________________________________________________________________________\n",
            "Example 2\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "___________________________________________________________________________________________________\n",
            "Baseline Human summary\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## good representation here\n",
        "\n",
        "example_indices = [40,200]\n",
        "\n",
        "dash_line = '_'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "  print(dash_line)\n",
        "  print('Example', i+1)\n",
        "  print(dash_line)\n",
        "  print('Input')\n",
        "  print(ds['test'][index]['dialogue'])\n",
        "  print(dash_line)\n",
        "  print('Baseline Human summary')\n",
        "  print(ds['test'][index]['summary'])\n",
        "  print()"
      ],
      "id": "noviQyIxVjlM"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "787cb225",
      "metadata": {
        "id": "787cb225"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ZBTjluliVjlN"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)"
      ],
      "id": "ZBTjluliVjlN"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DTlfVKD2VjlN",
        "outputId": "a9bc25c9-ee31-4d90-eb64-ada252e028d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n",
            "What time is it, Tom?\n"
          ]
        }
      ],
      "source": [
        "sentence ='What time is it, Tom?'\n",
        "\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "\n",
        "sentence_decoded = tokenizer.decode(sentence_encoded['input_ids'][0], skip_special_tokens= True)\n",
        "\n",
        "\n",
        "print(sentence_encoded['input_ids'][0])\n",
        "print(sentence_decoded)"
      ],
      "id": "DTlfVKD2VjlN"
    },
    {
      "cell_type": "code",
      "source": [
        "## random word decoding - for fun\n",
        "tensor1=torch.tensor([563, 19])\n",
        "\n",
        "sentence_decoded1 = tokenizer.decode(tensor1, skip_special_tokens= True)\n",
        "print(sentence_decoded1)"
      ],
      "metadata": {
        "id": "nDYCpV5biC7n",
        "outputId": "0c353e43-5ee8-46ee-ca99-a177754f62d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nDYCpV5biC7n",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = ds['test'][40]['dialogue']\n",
        "print(dialogue)\n",
        "summary = ds['test'][40]['summary']\n",
        "\n",
        "input = tokenizer(dialogue, return_tensors='pt')\n",
        "input_tensor = input['input_ids']\n",
        "\n",
        "output= model.generate(input_tensor, max_new_tokens = 500)\n"
      ],
      "metadata": {
        "id": "0V1q2Q5Nh1pI",
        "outputId": "ecb09528-c416-47c8-b14a-81cb5ec6309a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0V1q2Q5Nh1pI",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens= True)\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "id": "4mkL-poqn_L3",
        "outputId": "7718716b-2833-4b5b-83fb-daad71f7660e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4mkL-poqn_L3",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0, 5780,  536,   10,   94,   31,    7,    3,  324,   12, 4169,    5,\n",
            "            1]])\n",
            "Person1: It's ten to nine.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}