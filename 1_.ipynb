{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c02f3972",
      "metadata": {
        "id": "c02f3972"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchdata\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig\n",
        "import huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wlRY2Az6VjlM"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"knkarthick/dialogsum\")"
      ],
      "id": "wlRY2Az6VjlM"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noviQyIxVjlM",
        "outputId": "87005e76-2ecc-4d93-d0bf-65402472552e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________________________________________\n",
            "Example 1\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "___________________________________________________________________________________________________\n",
            "Baseline Human summary\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "___________________________________________________________________________________________________\n",
            "Example 2\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "___________________________________________________________________________________________________\n",
            "Baseline Human summary\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## good representation here\n",
        "\n",
        "example_indices = [40,200]\n",
        "\n",
        "dash_line = '_'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "  print(dash_line)\n",
        "  print('Example', i+1)\n",
        "  print(dash_line)\n",
        "  print('Input')\n",
        "  print(ds['test'][index]['dialogue'])\n",
        "  print(dash_line)\n",
        "  print('Baseline Human summary')\n",
        "  print(ds['test'][index]['summary'])\n",
        "  print()"
      ],
      "id": "noviQyIxVjlM"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "787cb225",
      "metadata": {
        "id": "787cb225"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ZBTjluliVjlN"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)"
      ],
      "id": "ZBTjluliVjlN"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTlfVKD2VjlN",
        "outputId": "a9bc25c9-ee31-4d90-eb64-ada252e028d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n",
            "What time is it, Tom?\n"
          ]
        }
      ],
      "source": [
        "sentence ='What time is it, Tom?'\n",
        "\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "\n",
        "sentence_decoded = tokenizer.decode(sentence_encoded['input_ids'][0], skip_special_tokens= True)\n",
        "\n",
        "\n",
        "print(sentence_encoded['input_ids'][0])\n",
        "print(sentence_decoded)"
      ],
      "id": "DTlfVKD2VjlN"
    },
    {
      "cell_type": "code",
      "source": [
        "## random word decoding - for fun\n",
        "tensor1=torch.tensor([563, 19])\n",
        "\n",
        "sentence_decoded1 = tokenizer.decode(tensor1, skip_special_tokens= True)\n",
        "print(sentence_decoded1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDYCpV5biC7n",
        "outputId": "0c353e43-5ee8-46ee-ca99-a177754f62d3"
      },
      "id": "nDYCpV5biC7n",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = ds['test'][41]['dialogue']\n",
        "print(dialogue)\n",
        "summary = ds['test'][41]['summary']\n",
        "\n",
        "input = tokenizer(dialogue, return_tensors='pt')\n",
        "input_tensor = input['input_ids']\n",
        "\n",
        "output= model.generate(input_tensor, max_new_tokens = 500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1q2Q5Nh1pI",
        "outputId": "93d0d427-46b5-49fc-c691-4603ff98bf07"
      },
      "id": "0V1q2Q5Nh1pI",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens= True)\n",
        "print('model summary : ', decoded_output)\n",
        "print('baseline summary: ',summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mkL-poqn_L3",
        "outputId": "16ffcce2-41cb-48e6-fdc2-1197c0fe2258"
      },
      "id": "4mkL-poqn_L3",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0, 5780,  536,   10,   94,   31,    7,    3,  324,   12, 4169,    5,\n",
            "            1]])\n",
            "model summary :  Person1: It's ten to nine.\n",
            "baseline summary:  #Person1# is rushing to catch a train but Tom thinks it isn't necessary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero shot inference\n",
        "instructing the model to perform a task"
      ],
      "metadata": {
        "id": "X7pMi63xvvMR"
      },
      "id": "X7pMi63xvvMR"
    },
    {
      "cell_type": "code",
      "source": [
        "## good representation here\n",
        "\n",
        "example_indices = [40,42]\n",
        "\n",
        "dash_line = '_'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "  dialogue = ds['test'][index]['dialogue']\n",
        "  summary = ds['test'][index]['summary']\n",
        "  prompt = f\"\"\"\n",
        "\n",
        "  summarize the following conversation :\n",
        "  {dialogue}\n",
        "\n",
        "  Summary:\n",
        "  \"\"\"\n",
        "\n",
        "  input = tokenizer(prompt, return_tensors='pt')\n",
        "  input_tensor = input['input_ids']\n",
        "\n",
        "  output= model.generate(input_tensor, max_new_tokens = 50)\n",
        "  decoded_output = tokenizer.decode(output[0], skip_special_tokens= True)\n",
        "  print(dash_line)\n",
        "  print('Example', i+1)\n",
        "  print(dash_line)\n",
        "  print('Input')\n",
        "  print(ds['test'][index]['dialogue'])\n",
        "  print(dash_line)\n",
        "  print('Zero shot model summary ')\n",
        "  print(decoded_output)\n",
        "  print('Baseline Human summary')\n",
        "  print(summary)\n",
        "  print()"
      ],
      "metadata": {
        "id": "L6h3TbwDvcM4",
        "outputId": "721fe6f1-068e-4b87-be7d-e030c81d1f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L6h3TbwDvcM4",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________________________________________\n",
            "Example 1\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "___________________________________________________________________________________________________\n",
            "Zero shot model summary \n",
            "The train is about to leave.\n",
            "Baseline Human summary\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "___________________________________________________________________________________________________\n",
            "Example 2\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: I don't know how to adjust my life. Would you give me a piece of advice?\n",
            "#Person2#: You look a bit pale, don't you?\n",
            "#Person1#: Yes, I can't sleep well every night.\n",
            "#Person2#: You should get plenty of sleep.\n",
            "#Person1#: I drink a lot of wine.\n",
            "#Person2#: If I were you, I wouldn't drink too much.\n",
            "#Person1#: I often feel so tired.\n",
            "#Person2#: You better do some exercise every morning.\n",
            "#Person1#: I sometimes find the shadow of death in front of me.\n",
            "#Person2#: Why do you worry about your future? You're very young, and you'll make great contribution to the world. I hope you take my advice.\n",
            "___________________________________________________________________________________________________\n",
            "Zero shot model summary \n",
            "Person1: I'm not sure how to adjust my life.\n",
            "Baseline Human summary\n",
            "#Person1# wants to adjust #Person1#'s life and #Person2# suggests #Person1# be positive and stay healthy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## good representation here\n",
        "\n",
        "example_indices = [40,42]\n",
        "\n",
        "dash_line = '_'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "  dialogue = ds['test'][index]['dialogue']\n",
        "  summary = ds['test'][index]['summary']\n",
        "  prompt = f\"\"\"\n",
        "\n",
        "  summarize the following conversation :\n",
        "  {dialogue}\n",
        "\n",
        "  what is going on here, tell what is happening:\n",
        "  \"\"\"\n",
        "\n",
        "  input = tokenizer(prompt, return_tensors='pt')\n",
        "  input_tensor = input['input_ids']\n",
        "\n",
        "  output= model.generate(input_tensor, max_new_tokens = 50)\n",
        "  decoded_output = tokenizer.decode(output[0], skip_special_tokens= True)\n",
        "  print(dash_line)\n",
        "  print('Example', i+1)\n",
        "  print(dash_line)\n",
        "  print('Input')\n",
        "  print(ds['test'][index]['dialogue'])\n",
        "  print(dash_line)\n",
        "  print('Zero shot model summary ')\n",
        "  print(decoded_output)\n",
        "  print('Baseline Human summary')\n",
        "  print(summary)\n",
        "  print()"
      ],
      "metadata": {
        "id": "LhF6A2fNvcLC",
        "outputId": "ce888856-eb0e-4d4e-c42c-ebb675809634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LhF6A2fNvcLC",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________________________________________\n",
            "Example 1\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "___________________________________________________________________________________________________\n",
            "Zero shot model summary \n",
            "#Person1: It's nine thirty.\n",
            "Baseline Human summary\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "___________________________________________________________________________________________________\n",
            "Example 2\n",
            "___________________________________________________________________________________________________\n",
            "Input\n",
            "#Person1#: I don't know how to adjust my life. Would you give me a piece of advice?\n",
            "#Person2#: You look a bit pale, don't you?\n",
            "#Person1#: Yes, I can't sleep well every night.\n",
            "#Person2#: You should get plenty of sleep.\n",
            "#Person1#: I drink a lot of wine.\n",
            "#Person2#: If I were you, I wouldn't drink too much.\n",
            "#Person1#: I often feel so tired.\n",
            "#Person2#: You better do some exercise every morning.\n",
            "#Person1#: I sometimes find the shadow of death in front of me.\n",
            "#Person2#: Why do you worry about your future? You're very young, and you'll make great contribution to the world. I hope you take my advice.\n",
            "___________________________________________________________________________________________________\n",
            "Zero shot model summary \n",
            "#Person1: I'm worried about my future.\n",
            "Baseline Human summary\n",
            "#Person1# wants to adjust #Person1#'s life and #Person2# suggests #Person1# be positive and stay healthy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjgLIIEzvcIq"
      },
      "id": "GjgLIIEzvcIq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Po0_VTdOvcGu"
      },
      "id": "Po0_VTdOvcGu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSiD4nhevcCX"
      },
      "id": "MSiD4nhevcCX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAxa0MFfvb-2"
      },
      "id": "gAxa0MFfvb-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAq_ZJ5_vb8K"
      },
      "id": "nAq_ZJ5_vb8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUF59N5Yvb5j"
      },
      "id": "EUF59N5Yvb5j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}